{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012f0e87",
   "metadata": {},
   "source": [
    "# Final project code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239371b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "import gensim\n",
    "import nltk\n",
    "import string \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe6d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_jsons/apple.json', 'r') as f:\n",
    "    apple_data = json.load(f)\n",
    "with open('training_jsons/google.json', 'r') as f:\n",
    "    google_data = json.load(f)\n",
    "with open('training_jsons/microsoft.json', 'r') as f:\n",
    "    microsoft_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b609ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all of the json\n",
    "data = apple_data + google_data + microsoft_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34304291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offer_status': 'No Offer', 'experience': 'Negative Experience', 'difficulty': 'Easy Interview', 'review': '10 minute speed run, very abrupt with unengaged interviewers. Asked behavioral questions and about previous projects. Describe a previous coding project, interests, Why Apple? \\n\\nDid not find this format engaging, thought I do like the efficiency of the structure. Interviewers did not seem to care or have enough time to get to know candidates', 'page': 120}\n"
     ]
    }
   ],
   "source": [
    "print(data[232]) #Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991a3731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No Offer', 'Declined Offer', 'Accepted Offer'}\n",
      "{'Negative Experience', 'Positive Experience', 'Neutral Experience'}\n",
      "{'Easy Interview', 'Average Interview', 'Difficult Interview'}\n"
     ]
    }
   ],
   "source": [
    "#View the three sets\n",
    "offer = set()\n",
    "experience = set()\n",
    "difficulty = set()\n",
    "for i in data:\n",
    "    offer.add(i[\"offer_status\"])\n",
    "    experience.add(i[\"experience\"])\n",
    "    difficulty.add(i[\"difficulty\"])\n",
    "print(offer)\n",
    "print(experience)\n",
    "print(difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5803c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1, 0, 1, 1]\n",
      "{'experience': 'Positive Experience', 'difficulty': 'Average Interview', 'review': 'initial phone interview 15mins received an email 2 days after applying inviting me to schedule a time to call with an apple retail recruiter who was based in california applying for job in texas was told at the end of the phone call that i would be advancing to the next step invited to an optional get to know apple web event 30mins which went over some basics about working in apple retail and company culturegroup interview 45mins group interview with manager from the apple store i was applying to and 3 other interviewees 4 interviewees total took place online via their webex platform similar to zoom as of aug 2021 most interviewees were online 105 minutes before the interview was scheduled to begin and an icebreaker question was asked about a minute before the scheduled start time the invite email suggested we use a digital background for our own privacy most felt comfortable without it a question would be asked and we would each take turns answering in any order we pleased questions were situationbased', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "#Clean Data\n",
    "y = []\n",
    "X = []\n",
    "#0 represents no offer\n",
    "#1 represents declined offer or accepted offer\n",
    "\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #Remove \\w \\s \\n\n",
    "    data[i][\"review\"] = data[i][\"review\"].strip().replace('\\n', '').replace('\\r', '').lower()\n",
    "    data[i][\"review\"] = re.sub(r'[^\\w\\s\\n\\r]', '', data[i][\"review\"]).strip()\n",
    "    #Remove links\n",
    "    data[i][\"review\"] = re.sub(r'(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '', data[i][\"review\"])\n",
    "    if data[i][\"offer_status\"] == 'No Offer':\n",
    "        data[i][\"offer_status\"] = 0\n",
    "        y.append(0)\n",
    "    else:\n",
    "        data[i][\"offer_status\"] = 1\n",
    "        y.append(1)\n",
    "    del data[i]['offer_status']\n",
    "print(y[1:10])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e234e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of No Offers: 19810\n",
      "Percentage of No Offers: 64.29730606945797\n"
     ]
    }
   ],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "for i in y:\n",
    "    if i == 1:\n",
    "        count1+=1\n",
    "    else:\n",
    "        count0+=1\n",
    "print(\"Number of No Offers:\", count0)\n",
    "print(\"Percentage of No Offers:\", (count0/(count1+count0))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "715e23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa98be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f84a709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dinakartalluri/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Define pretrained model\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89b667b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the lexicon feature\n",
    "\n",
    "def lexicon_feature(embed, tokens, word1, word2, t_p, t_n, pos_words, neg_words):\n",
    "    pos_pole = np.zeros((300,), dtype=float)\n",
    "    p_count = 0\n",
    "    neg_pole = np.zeros((300,), dtype=float)\n",
    "    n_count = 0\n",
    "    #Found synonyms on words on thesauras.com\n",
    "    \n",
    "    for word in pos_words:\n",
    "        if word in embed:\n",
    "            pos_pole+=embed[word]\n",
    "            p_count+=1\n",
    "    \n",
    "    for word in neg_words:\n",
    "        if word in embed:\n",
    "            neg_pole+=embed[word]\n",
    "            n_count+=1\n",
    "    \n",
    "    pos_pole/= p_count\n",
    "    neg_pole/= n_count\n",
    "            \n",
    "    length = len(tokens)\n",
    "    pos_words_count = 0\n",
    "    neg_words_count = 0\n",
    "    \n",
    "    axis = pos_pole - neg_pole\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in embed:\n",
    "            embed_word = embed[token]\n",
    "            cos_similarity = np.dot(embed_word, axis)/(np.linalg.norm(embed_word)*np.linalg.norm(axis))\n",
    "            if cos_similarity > t_p:\n",
    "                pos_words_count+=1\n",
    "            elif cos_similarity < t_n:\n",
    "                neg_words_count+=1\n",
    "    pos_words_count/=length\n",
    "    neg_words_count/=length\n",
    "    \n",
    "    return pos_words_count, neg_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e00d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "\n",
    "def extract_features(embed, data, include, sid):\n",
    "    X_features = np.zeros((len(data), 6))\n",
    "    if not include:\n",
    "        X_features = np.zeros((len(data), 3))\n",
    "    for i, d in enumerate(data):\n",
    "        feature_1 = 0\n",
    "        feature_2 = 0\n",
    "\n",
    "        if d[\"experience\"] == \"Positive Experience\":\n",
    "            feature_1 = 1\n",
    "        elif d[\"experience\"] == \"Negative Experience\":\n",
    "            feature_1 = -1\n",
    "\n",
    "        if d[\"difficulty\"] == \"Easy Interview\":\n",
    "            feature_2 = 1\n",
    "        elif d[\"difficulty\"] == \"Difficult Interview\":\n",
    "            feature_2 = -1\n",
    "        \n",
    "        tokenized = word_tokenize(d[\"review\"])\n",
    "        stopwords_english = stopwords.words('english')\n",
    "        \n",
    "        feature_3 = 0\n",
    "        number_embed = 0\n",
    "        tokens = []\n",
    "        for token in tokenized:\n",
    "            if token not in stopwords_english and token not in string.punctuation and token[0].isdigit() == False:\n",
    "                if token in embed:\n",
    "                    tokens.append(token)\n",
    "                    feature_3+=embed[token]\n",
    "                    number_embed+=1\n",
    "        feature_3/=number_embed\n",
    "        feature_3 = np.array(feature_3).mean()\n",
    "        \n",
    "        out = sid.polarity_scores(d[\"review\"])\n",
    "        feature_4 = out['compound']\n",
    "        \n",
    "        pos_words = [\"accomplishment\", \"advance\", \"benefit\", \"gain\", \"happiness\", \"progress\", \"triumph\", \"victory\", \"win\"]\n",
    "        neg_words = [\"breakdown\", \"collapse\", \"decline\", \"defeat\", \"loss\", \"misstep\", \"deterioration\"]\n",
    "        pos_count, neg_count = lexicon_feature(embed, tokens, \"success\", \"failure\", 0.2, -0.2, pos_words, neg_words)\n",
    "        #Check the ranges of +-0.4, +-0.3, and +-0.2 to figure out which ones look better (+-0.2 much better)\n",
    "        if include:\n",
    "            X_features[i] = np.array([feature_1, feature_2, feature_3, feature_4, pos_count, neg_count])\n",
    "        else:\n",
    "            X_features[i] = np.array([feature_1, feature_2, feature_3])\n",
    "    return X_features\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e2637e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -1.        , -0.00293171,  0.9979    ,  0.00236407,\n",
       "        0.00472813])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the features\n",
    "\n",
    "X_train_features_with_i = extract_features(embed, X_train, True, sid)\n",
    "X_test_features_with_i = extract_features(embed, X_test, True, sid)\n",
    "X_train_features_with_i[100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "836376f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6703810274602549\n",
      "best parameters  {'C': 0.01, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#fit LR, hyperparam tuning\n",
    "params={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "lr=LogisticRegression(solver='liblinear')\n",
    "lr_cv=GridSearchCV(lr,params,cv=10)\n",
    "lr_cv.fit(X_train_features_with_i,y_train)\n",
    "print(\"accuracy :\",lr_cv.best_score_)\n",
    "print(\"best parameters \",lr_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a0a080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature selection with Logistic Regression\n",
    "sel_ = SelectFromModel(LogisticRegression(C=lr_cv.best_params_['C'], penalty=lr_cv.best_params_['penalty'], solver='liblinear'))\n",
    "sel_.fit(X_train_features_with_i, y_train)\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924817f",
   "metadata": {},
   "source": [
    "#### Without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09b52758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6222392423386456\n",
      "0.6608969315499607\n",
      "0.6608969315499607\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01,penalty=\"l2\")\n",
    "lr.fit(X_train_features_with_i,y_train)\n",
    "y_pred = lr.predict(X_test_features_with_i)\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2acd7a",
   "metadata": {},
   "source": [
    "#### With feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2250a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6315096657659055\n",
      "0.6606018882769473\n",
      "0.6606018882769473\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_features_with_i[:, [0,1,3]],y_train)\n",
    "y_pred = lr.predict(X_test_features_with_i[:, [0,1,3]])\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0abd9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFNN hyperparam tuning\n",
    "def nn_hyperparameter_tuning(X, y):\n",
    "    \n",
    "    hyperparameters = [[(16,8), 0.001, 0.001],[(16,8), 0.01, 0.01], [(32,8), 0.01, 0.001], [(32,8), 0.001, 0.01]]\n",
    "    best_score = 0\n",
    "    best_hyperparameter = {'hidden_layer': 0, 'initial_lr': 0, 'reg_strength': 0}\n",
    "    \n",
    "    for params in hyperparameters:\n",
    "        clf = MLPClassifier(hidden_layer_sizes=params[0], learning_rate_init=params[1], alpha=params[2],activation='relu', tol=1e-3, solver = 'adam')\n",
    "        score = cross_val_score(clf, X, y, cv=5, scoring= 'f1_macro').mean()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_hyperparameter['hidden_layer'] = params[0]\n",
    "            best_hyperparameter['initial_lr'] = params[1]\n",
    "            best_hyperparameter['reg_strength'] = params[2]\n",
    "        print(\"Score: \", score)\n",
    "    \n",
    "    return best_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "792deb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5842112481866875\n",
      "Score:  0.5737561544006925\n",
      "Score:  0.5716751360468451\n",
      "Score:  0.5906239668109957\n"
     ]
    }
   ],
   "source": [
    "#Best params\n",
    "hyperparameter = nn_hyperparameter_tuning(X_train_features_with_i, y_train)\n",
    "hidden_layers = hyperparameter['hidden_layer']\n",
    "lr = hyperparameter['initial_lr']\n",
    "reg = hyperparameter['reg_strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9acdec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8) 0.001 0.01\n"
     ]
    }
   ],
   "source": [
    "print(hidden_layers, lr, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c4853",
   "metadata": {},
   "source": [
    "#### With feature selection (random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e352b325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433281612562637\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "lst = [[0,1,2,3,4], [0,1,3,4], [3,4,5], [0,1,4,5], [0,1,3], [1,3,5], [0,2,4]]\n",
    "best_score = 0\n",
    "best_i = 0\n",
    "for i in lst:\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layers, learning_rate_init=lr, alpha=reg,activation='relu', tol=1e-3, solver = 'adam').fit(X_train_features_with_i[:,i],y_train)\n",
    "    y_pred_nn = clf.predict(X_test_features_with_i[:,i])\n",
    "    score = f1_score(y_test, y_pred_nn, average='weighted')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_i = i\n",
    "print(best_score)\n",
    "print(best_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec3d88",
   "metadata": {},
   "source": [
    "#### Without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d846f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311704310228133\n",
      "0.6612903225806451\n",
      "0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=hidden_layers, learning_rate_init=lr, alpha=reg,activation='relu', tol=1e-3, solver = 'adam').fit(X_train_features_with_i,y_train)\n",
    "y_pred_nn = clf.predict(X_test_features_with_i)\n",
    "print(f1_score(y_test, y_pred_nn, average='weighted'))\n",
    "print(f1_score(y_test, y_pred_nn, average='micro'))\n",
    "print(accuracy_score(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff766435",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83f57dd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -1.        , -0.00293171])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features_baseline = extract_features(embed, X_train, False, sid)\n",
    "X_test_features_baseline = extract_features(embed, X_test, False, sid)\n",
    "X_train_features_baseline[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794420e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5890877960465329\n",
      "0.6569630212431157\n",
      "0.6569630212431157\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01,penalty=\"l2\")\n",
    "lr.fit(X_train_features_baseline,y_train)\n",
    "y_pred = lr.predict(X_test_features_baseline)\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
